# Netflix Data Analysis Project

> End-to-End Data Pipeline with DBT, Snowflake, and AWS S3

[![DBT](https://img.shields.io/badge/DBT-FF694B?style=for-the-badge&logo=dbt&logoColor=white)](https://www.getdbt.com/)
[![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white)](https://www.snowflake.com/)
[![AWS S3](https://img.shields.io/badge/AWS_S3-569A31?style=for-the-badge&logo=amazons3&logoColor=white)](https://aws.amazon.com/s3/)

## ğŸ“‹ Project Overview

A comprehensive data analytics pipeline simulating Netflix data analysis using modern data engineering tools. This project demonstrates the **ELT (Extract, Load, Transform)** paradigm, leveraging AWS S3 for storage, Snowflake as the data warehouse, and DBT for transformation logic.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data  â”‚ â”€â”€â”€> â”‚   AWS S3     â”‚ â”€â”€â”€> â”‚  Snowflake  â”‚ â”€â”€â”€> â”‚ DBT Models   â”‚
â”‚  (CSV Files)â”‚      â”‚   (Storage)  â”‚      â”‚  (RAW Layer)â”‚      â”‚ (Transformed)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

- **Storage**: AWS S3
- **Data Warehouse**: Snowflake
- **Transformation**: DBT (Data Build Tool)
- **Language**: SQL

### Data Flow

```
Raw Data â†’ S3 Bucket â†’ Snowflake (RAW Schema) â†’ Staging Layer â†’ Development Zone
```

## ğŸ“Š Dataset

**MovieLens 20M Dataset** simulating Netflix analytics:

| Component | Records | Description |
|-----------|---------|-------------|
| Ratings | 20M | User ratings with timestamps |
| Tags | 465K | User-generated movie tags |
| Movies | 20K | Movie metadata with genres |
| Users | 138K | Unique user identifiers |
| Links | - | External movie identifiers |
| Genome Tags/Scores | - | Tag relevance metrics |

**Files:**
- `ratings.csv`
- `tags.csv`
- `movies.csv`
- `links.csv`
- `genome_tags.csv`
- `genome_scores.csv`

## ğŸš€ Implementation Steps

### 1. Data Extraction & Storage

```bash
# Setup AWS S3
- Create S3 bucket
- Upload MovieLens CSV files
- Configure AWS credentials
```

### 2. Snowflake Configuration

**Database Structure:**
```
MOVIELENS
â”œâ”€â”€ RAW (Landing zone)
â”œâ”€â”€ DEV (Transformed models)
â””â”€â”€ SNAPSHOTS (Historical tracking)
```

**Setup Commands:**
```sql
-- Create roles and users
CREATE ROLE TRANSFORM;
CREATE USER dbt PASSWORD='***';

-- Create database and schemas
CREATE DATABASE MOVIELENS;
CREATE SCHEMA MOVIELENS.RAW;
CREATE SCHEMA MOVIELENS.DEV;

-- Grant permissions
GRANT ALL ON DATABASE MOVIELENS TO ROLE TRANSFORM;
```

**Load Data:**
```sql
COPY INTO RAW.RAW_MOVIES
FROM @s3_stage/movies.csv
FILE_FORMAT = (TYPE = 'CSV' SKIP_HEADER = 1);
```

### 3. DBT Setup

**Installation:**
```bash
# Create virtual environment
python -m venv dbtenv
source dbtenv/bin/activate  # Windows: dbtenv\Scripts\activate

# Install DBT with Snowflake adapter
pip install dbt-snowflake

# Initialize project
dbt init my_dbt_project
```

**Project Structure:**
```
my_dbt_project/
â”œâ”€â”€ analyses/          # Ad-hoc analytical queries
â”œâ”€â”€ macros/            # Reusable SQL functions
â”œâ”€â”€ models/            # Transformation models
â”‚   â”œâ”€â”€ staging/       # Source staging models
â”‚   â”œâ”€â”€ dimensions/    # Dimension tables
â”‚   â””â”€â”€ facts/         # Fact tables
â”œâ”€â”€ seeds/             # Static reference data
â”œâ”€â”€ snapshots/         # SCD Type 2 tracking
â”œâ”€â”€ tests/             # Custom data tests
â”œâ”€â”€ dbt_project.yml    # Project configuration
â””â”€â”€ packages.yml       # DBT packages
```

### 4. Data Models

#### Staging Layer (Views)

```sql
-- src_movies.sql
SELECT
    movieId AS movie_id,
    title,
    genres
FROM {{ source('raw', 'raw_movies') }}
```

**Models:**
- `src_movies`
- `src_ratings`
- `src_tags`
- `src_links`
- `src_genome_tags`
- `src_genome_scores`

#### Dimension Tables (Tables)

```sql
-- dim_movies.sql
{{
    config(
        materialized='table'
    )
}}

SELECT
    movie_id,
    title,
    SPLIT(genres, '|') AS genre_array
FROM {{ ref('src_movies') }}
```

**Models:**
- `dim_movies`: Movie metadata
- `dim_users`: User dimension
- `dim_genome_tags`: Tag taxonomy

#### Fact Tables (Incremental)

```sql
-- fct_ratings.sql
{{
    config(
        materialized='incremental',
        unique_key='rating_id'
    )
}}

SELECT
    user_id,
    movie_id,
    rating,
    rated_at
FROM {{ ref('src_ratings') }}

{% if is_incremental() %}
WHERE rated_at > (SELECT MAX(rated_at) FROM {{ this }})
{% endif %}
```

**Models:**
- `fct_ratings`: User ratings (incremental)
- `fct_genome_scores`: Tag relevance scores

### 5. Seeds

```bash
# Load static reference data
dbt seed
```

**Seed Files:**
- `seed_movie_release_dates.csv`

### 6. Snapshots (SCD Type 2)

```sql
-- snap_tags.sql
{% snapshot snap_tags %}

{{
    config(
        target_schema='snapshots',
        unique_key='tag_id',
        strategy='timestamp',
        updated_at='updated_at'
    )
}}

SELECT * FROM {{ ref('src_tags') }}

{% endsnapshot %}
```

**Execute:**
```bash
dbt snapshot
```

### 7. Data Quality Tests

**Schema Tests (schema.yml):**
```yaml
models:
  - name: dim_movies
    columns:
      - name: movie_id
        tests:
          - unique
          - not_null
      
  - name: fct_ratings
    columns:
      - name: movie_id
        tests:
          - relationships:
              to: ref('dim_movies')
              field: movie_id
```

**Custom Tests:**
```sql
-- tests/relevance_score_test.sql
SELECT *
FROM {{ ref('fct_genome_scores') }}
WHERE relevance_score <= 0
```

**Run Tests:**
```bash
dbt test
```

### 8. Documentation

```bash
# Generate documentation
dbt docs generate

# Serve documentation locally
dbt docs serve
# Access at http://localhost:8080
```

**Features:**
- Interactive lineage graphs
- Model descriptions
- Column metadata
- Test coverage
- Data profiling

### 9. Analysis Queries

```sql
-- analyses/movie_analysis.sql
WITH ratings_summary AS (
    SELECT
        movie_id,
        AVG(rating) AS average_rating,
        COUNT(*) AS total_ratings
    FROM {{ ref('fct_ratings') }}
    GROUP BY movie_id
    HAVING COUNT(*) > 100
)

SELECT
    m.movie_title,
    rs.average_rating,
    rs.total_ratings
FROM ratings_summary rs
JOIN {{ ref('dim_movies') }} m
ON rs.movie_id = m.movie_id
ORDER BY rs.average_rating DESC;
```

**Compile:**
```bash
dbt compile
# Find compiled SQL in target/compiled/
```

### 10. Macros

```sql
-- macros/generate_surrogate_key.sql
{% macro generate_surrogate_key(field_list) %}
    {{ dbt_utils.generate_surrogate_key(field_list) }}
{% endmacro %}
```

**Install Packages:**
```yaml
# packages.yml
packages:
  - package: dbt-labs/dbt_utils
    version: 1.0.0
```

```bash
dbt deps
```

## ğŸ¯ Key Features

### âœ… Modular Design
- Clear separation between staging, dimension, and fact layers
- Reusable models using DBT's `ref()` function

### âœ… Incremental Processing
- Efficient updates for large fact tables
- Timestamp-based incremental logic

### âœ… Historical Tracking
- SCD Type 2 implementation via snapshots
- Maintains complete data history

### âœ… Data Quality
- Comprehensive test coverage
- Automated quality checks on every run

### âœ… Documentation
- Auto-generated interactive docs
- Visual lineage graphs
- Complete metadata catalog

### âœ… Code Reusability
- Macros for common transformations
- DRY principles throughout

### âœ… Security
- Role-based access control
- Least privilege principles

## ğŸ“ˆ Project Metrics

- **Records Processed**: 20M+ ratings
- **Models Created**: 15+
- **Tests Implemented**: 13+
- **Data Quality**: 100% test coverage
- **Documentation**: Fully automated

## ğŸ”§ Usage

### Run All Models
```bash
dbt run
```

### Run Specific Model
```bash
dbt run --select dim_movies
```

### Run Tests
```bash
dbt test
```

### Generate Documentation
```bash
dbt docs generate
dbt docs serve
```

### Run Snapshots
```bash
dbt snapshot
```

### Full Refresh
```bash
dbt run --full-refresh
```

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ analyses/
â”‚   â””â”€â”€ movie_analysis.sql
â”œâ”€â”€ macros/
â”‚   â””â”€â”€ custom_macros.sql
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ src_movies.sql
â”‚   â”‚   â”œâ”€â”€ src_ratings.sql
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ dimensions/
â”‚   â”‚   â”œâ”€â”€ dim_movies.sql
â”‚   â”‚   â”œâ”€â”€ dim_users.sql
â”‚   â”‚   â””â”€â”€ dim_genome_tags.sql
â”‚   â””â”€â”€ facts/
â”‚       â”œâ”€â”€ fct_ratings.sql
â”‚       â””â”€â”€ fct_genome_scores.sql
â”œâ”€â”€ seeds/
â”‚   â””â”€â”€ seed_movie_release_dates.csv
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ snap_tags.sql
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ relevance_score_test.sql
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ packages.yml
â””â”€â”€ README.md
```

## ğŸ“ Learning Outcomes

- **ELT Paradigm**: Transform after load strategy
- **Dimensional Modeling**: Star schema implementation
- **Version Control**: SQL-based transformation logic
- **Data Lineage**: Automatic dependency management
- **Testing**: Data quality assurance practices
- **Documentation**: Self-documenting data pipelines

## ğŸ“¸ Screenshots

### DBT Documentation Interface
Interactive documentation with model metadata, column descriptions, and test results.

### Lineage Graph
Visual representation of data flow from source tables through staging to final models.

### Snowflake Dashboard
Complete setup with raw tables, views, and snapshot tables organized by schema.

### VS Code Project Structure
Organized DBT project with all components clearly separated.

## ğŸš€ Future Enhancements

- [ ] Add more advanced analytics models
- [ ] Implement data monitoring and alerts
- [ ] Add CI/CD pipeline integration
- [ ] Expand test coverage
- [ ] Add performance optimization
- [ ] Implement data mart layers

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ‘¤ Author

**Shivsharan Patil**
- GitHub: [@yourusername](https://github.com/shivshaa)
- LinkedIn: [Shivsharan_Patil]([https://linkedin.com/in/yourprofile](https://www.linkedin.com/in/shivsharan-patil-6435a1181/))

## ğŸ™ Acknowledgments

- MovieLens dataset by GroupLens Research
- AWS S3 Datalake storage for raw data
- DBT Labs for the amazing transformation tool
- Snowflake for cloud data warehouse platform

---

â­ If you found this project helpful, please give it a star!

ğŸ“§ For questions or feedback, feel free to open an issue.
